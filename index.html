<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Data by Daniel</title>

  <!-- AOS for scroll animations -->
  <link rel="stylesheet" href="https://unpkg.com/aos@2.3.1/dist/aos.css" />

  <!-- Plotly for interactive charts -->
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>

  <!-- Main CSS -->
  <link rel="stylesheet" href="styles.css" />
</head>
<body>

  <!-- Fixed Navigation -->
  <header class="site-header">
    <div class="nav-brand">Data by Daniel</div>
    <nav class="nav-links">
      <a href="#resume">Resume</a>
      <a href="#projects">Projects</a>
      <a href="#contact">Contact</a>
    </nav>
  </header>

  <!-- Hero / Call to Action -->
  <section class="hero-section" id="top">
    <div class="hero-content" data-aos="fade-up" data-aos-duration="900">
      <h1 class="hero-title">Crafting Insights from Everyday Data</h1>
      <p class="hero-subtitle">
        Hi, I'm Daniel! If you're reading this, there's a chance that you may be hiring 
        a data analyst, project manager, or any of the wide variety of roles that exist in 
        between. If so, scroll down to find out why, in my humble opinion, you should consider hiring me!
      </p>
      <p class="cta-contact">
        <strong>Email:</strong> <a href="mailto:dmindlin824@gmail.com">dmindlin824@gmail.com</a> &nbsp;|&nbsp; 
        <strong>Phone:</strong> <a href="tel:8186658871">818-665-8871</a>
      </p>
      <a href="#resume" class="cta-button" data-aos="zoom-in" data-aos-duration="600" data-aos-delay="300">
        Discover My Work
      </a>
    </div>
    <!-- Hero Background Image (relative path for GitHub Pages) -->
    <img 
      src="./images/hans-jurgen-mager-qQWV91TTBrE-unsplash.jpg"
      alt="Hero Background Image" 
      class="hero-bg" 
    />
  </section>

  <!-- Resume Section (Dynamic Timeline) -->
  <section class="resume-section" id="resume">
    <div class="section-container" data-aos="fade-up" data-aos-duration="900">
      <h2>Professional Timeline</h2>
      <p>
        Below is a chronological look at my experience, covering key data roles,
        small-scale project coordination responsibilities, and an overall perspective 
        on how analytics can transform practical problems into real solutions.
      </p>

      <div class="timeline">
        <!-- NationsBenefits -->
        <div class="timeline-block" data-aos="fade-up" data-aos-duration="900" data-aos-delay="100">
          <div class="timeline-content">
            <h3>NationsBenefits (October 2024 - February 2025)</h3>
            <p class="timeline-sub">Senior Data Analyst</p>
            <p>
              Venturing into the healthcare realm, I constructed SQL/Python pipelines 
              that cleansed and modeled large-scale data for Elevance and Aetna, boosting 
              data accuracy by ~20%. In my junior capacity, I shouldered day-to-day planning 
              responsibilities—coordinating minor sprints, aligning tasks with the business 
              team, and ensuring that each data milestone was appropriately validated. My 
              Power BI and Tableau dashboards supported multi-million-dollar strategic 
              initiatives, improving efficiency by ~15%.
            </p>
            <p>
              I also implemented iterative transformations with dbt (a data build tool)
              to streamline data extraction, raising processing efficiency another ~15–20%.
              During this period, I learned to blend standard regression and hypothesis 
              testing (pandas, scikit-learn, SciPy) into everyday workflows, accelerating 
              data-driven decisions at the C-level. Although I was an associate-level 
              contributor, I actively planned pipeline enhancement tasks to ensure on-time 
              delivery and a coherent data journey from ingestion to final insights.
            </p>
          </div>
          <div class="timeline-badge"></div>
        </div>

        <!-- CDI Advisors -->
        <div class="timeline-block" data-aos="fade-up" data-aos-duration="900" data-aos-delay="200">
          <div class="timeline-content">
            <h3>CDI Advisors (January 2024 - September 2024)</h3>
            <p class="timeline-sub">Senior Data Analyst (Contract)</p>
            <p>
              As a contract Senior Data Analyst working alongside a tight-knit team, 
              I focused on forecasting solutions using Python libraries like pandas, 
              scikit-learn, and XGBoost, cutting forecast errors by about 10%. 
              I introduced SAS-based accuracy checks to refine existing forecasting processes, 
              and used dbt in conjunction with Airflow on a modest AWS/Snowflake environment 
              for ~20–25% overall workflow efficiency gains.
            </p>
            <p>
              My responsibilities included running short weekly stand-ups, setting 
              small deadlines, and verifying deliverables matched stakeholder expectations.
              This experience taught me how iterative improvements and consistent 
              communication can elevate forecast fidelity—even in a local or mid-scale environment.
            </p>
          </div>
          <div class="timeline-badge"></div>
        </div>

        <!-- Royal Caribbean Group -->
        <div class="timeline-block" data-aos="fade-up" data-aos-duration="900" data-aos-delay="300">
          <div class="timeline-content">
            <h3>Royal Caribbean Group (September 2023 - December 2023)</h3>
            <p class="timeline-sub">Senior Data Analyst (Contract)</p>
            <p>
              At Royal Caribbean Group, I devised SQL/Python revenue models for a fleet 
              of 26 ships, elevating demand projection accuracy by ~15–20%. I also 
              scripted Python-based ticket pricing updates, reducing manual input by ~30–40% 
              and enhancing operational efficiency by ~10–15%. In my associate role, I 
              tracked each deliverable's progress (like implementing advanced window 
              functions) in short sprints, ensuring code quality and data integrity 
              before deployment.
            </p>
            <p>
              This environment prioritized fast decisions, so I coordinated with 
              operations to confirm pipeline readiness each week. By bridging data 
              engineering tasks and simple project management duties, I helped deliver 
              near real-time fare adjustments and quickly capitalized on new 
              revenue opportunities.
            </p>
          </div>
          <div class="timeline-badge"></div>
        </div>

        <!-- CVS Health -->
        <div class="timeline-block" data-aos="fade-up" data-aos-duration="900" data-aos-delay="400">
          <div class="timeline-content">
            <h3>CVS Health (May 2022 - January 2023)</h3>
            <p class="timeline-sub">Analytics Consultant</p>
            <p>
              Taking on a consulting role at CVS Health, I worked with SQL (including advanced
              window functions, CTEs) and Python-based libraries (pandas, scikit-learn)
              to optimize multi-team data workflows on local or minimal hardware setups. 
              My duties involved clarifying each ingestion or transformation task 
              in a backlog and verifying final outputs within specified deadlines.
            </p>
            <p>
              By deploying scalable data pipelines (Airflow, dbt), I reduced manual data handling, 
              allowing teams to focus on strategic data usage. I further integrated ML models 
              (TensorFlow, XGBoost) for forecasting. While others determined the vision, 
              I collaborated closely with them, ensuring my small-scale management 
              approach kept daily tasks on target, culminating in a better overall pipeline 
              for timely analytics.
            </p>
          </div>
          <div class="timeline-badge"></div>
        </div>

        <!-- Qvest.US -->
        <div class="timeline-block" data-aos="fade-up" data-aos-duration="900" data-aos-delay="500">
          <div class="timeline-content">
            <h3>Qvest.US (July 2021 - March 2022)</h3>
            <p class="timeline-sub">Consulting Analyst</p>
            <p>
              At Qvest.US, I stepped into an associate-level data analyst role supporting 
              SQL-driven data pipelines for cross-department Tableau/Power BI dashboards. 
              These pipelines fostered real-time insights for sales and operations. 
              My self-organized “micro-projects” for each enhancement ensured tasks remained 
              bite-sized and trackable, so stakeholders saw incremental gains every two weeks.
            </p>
            <p>
              I also ran market and competitive analyses with Python scripts, 
              enabling data-backed strategy formation. Although I juggled 
              typical junior analytics tasks, I found that minimal but structured 
              project planning (like short stand-ups and Gantt charts) significantly 
              boosted visibility and maintained progress across concurrent tasks.
            </p>
          </div>
          <div class="timeline-badge"></div>
        </div>

        <!-- Education & Skills -->
        <div class="timeline-block" data-aos="fade-up" data-aos-duration="900" data-aos-delay="600">
          <div class="timeline-content">
            <h3>Education &amp; Skills</h3>
            <p class="timeline-sub">Core Foundations</p>
            <p>
              <strong>B.S. in Statistics &amp; B.A. in History</strong>, UC Santa Barbara (August 2020)<br/>
              <strong>M.S. in Business Analytics</strong>, University of San Diego (May 2021)
            </p>
            <p>
              <strong>Skills:</strong> SQL, Python, dbt, Airflow, scikit-learn, 
              Tableau, Power BI, AWS, Azure, BigQuery, ETL/ELT, Data Visualization,
              Machine Learning
            </p>
            <p>
              <strong>Certifications:</strong> Salesforce Certified Administrator, 
              Salesforce Certified Advanced Administrator, AWS Certified Cloud Practitioner
            </p>
          </div>
          <div class="timeline-badge"></div>
        </div>
      </div>
    </div>
  </section>

  <!-- Projects Section -->
  <section class="projects-section" id="projects">
    <div class="section-container" data-aos="fade-up" data-aos-duration="900">
      <h2>Independent Projects</h2>
      <p>
        Every dataset tells a story—sometimes it’s about shifting consumer behavior, 
        sometimes it's a pattern hidden in millions of transactions, and sometimes 
        it’s the unexpected signal buried in the noise. The projects below are deep 
        dives into real-world datasets, where I’ve unraveled trends, built predictive 
        models, and extracted meaningful insights from raw numbers.
      </p>
      <p>
        Each project tackles a unique analytical challenge, from forecasting demand 
        to deciphering sentiment at scale. The goal isn’t just to process data—it’s 
        to illuminate patterns, solve problems, and turn numbers into decisions.
      </p>
      <p>
        What follows are three detailed case studies. You’ll see how I approach complex 
        problems, the logic behind my analyses, and the key takeaways that transform 
        data into strategy. Technical concepts are explained along the way, ensuring 
        that whether you're a fellow data analyst or just curious about the power of 
        analytics, you’ll walk away with a clear understanding of how these projects 
        deliver real, actionable insights.
      </p>

      <!-- Project 1: Sentiment Analysis on 1.6 Million Tweets -->
      <div class="project-card" data-aos="fade-up" data-aos-duration="900" data-aos-delay="100">
        <div class="project-details animated-panel">
          <h3>1. Sentiment Analysis on 1.6 Million Tweets</h3>
          <p>
            <strong>Project Overview:</strong> This project aimed to determine overall sentiment 
            (positive, neutral, or negative) from a large corpus of tweets. I used Python, 
            pandas, and scikit-learn to handle data ingestion, text cleaning, and feature extraction. 
            I sought to highlight how emotional tone evolves in response to trending events 
            or viral hashtags.
          </p>
          <p>
            <strong>Process:</strong> 
            I began by removing noise in the text data—symbols, repeated characters, 
            and extraneous whitespace. Next, I performed tokenization (splitting each tweet into words), 
            building a vocabulary that was transformed via TF-IDF (term frequency-inverse document frequency) 
            to highlight distinctive words. A logistic regression classifier was trained and tuned using 
            cross-validation (repeatedly splitting the dataset to test model generality). This approach 
            uncovered strong correlations between negative sentiment spikes and certain trending topics.
          </p>
          <p>
            <strong>Results &amp; Insights:</strong>
            The final model reached roughly 92% accuracy on a hold-out set. A timeline analysis confirmed 
            that sentiment dips correlated with contentious news cycles, while positive peaks 
            often followed lighthearted announcements. By overlaying retweet counts, I discovered 
            that strongly negative tweets were more likely to be amplified, shining a light 
            on the role of social networks in driving polarizing discussions.
          </p>
          <div id="textAnalysisChart" class="vis-container"></div>
          <p>
            <em>Visualization: Monthly Average Sentiment &amp; Retweet Volume</em><br/>
            The left axis below tracks how overall sentiment (ranging -1 to +1) fluctuated 
            month by month, while the right axis plots total retweet volume. Notably, 
            months with more extreme negative sentiment also showed a surge in retweets, 
            illustrating how emotional content tends to garner greater user engagement.
          </p>
        </div>
      </div>

      <!-- Project 2: Time Series Forecasting for Retail Demand -->
      <div class="project-card" data-aos="fade-up" data-aos-duration="900" data-aos-delay="200">
        <div class="project-details animated-panel">
          <h3>2. Time Series Forecasting for Retail Demand</h3>
          <p>
            <strong>Project Overview:</strong>
            Working with two years of daily sales data across multiple product lines, 
            I used Python’s time-series libraries and advanced regressors to predict 
            monthly demand. By pinpointing future peaks and troughs more accurately, 
            managers could optimize inventory and cut down on emergency shipping costs.
          </p>
          <p>
            <strong>Process:</strong>
            After carefully filtering out anomalies (e.g., data entry errors, returns, 
            or flash promotions) and normalizing numeric features, I leveraged 
            a combination of Prophet (for seasonality detection) and RandomForestRegressor 
            (to capture non-linear interactions). By assembling an “ensemble” from both, 
            I systematically tested performance via rolling window back-tests over 24 months. 
            Promotion flags, weekend/weekday splits, and store-level weighting factors 
            all contributed to the final predictive model.
          </p>
          <p>
            <strong>Results &amp; Insights:</strong>
            This ensemble approach delivered a ~17% improvement in MAE (mean absolute error), 
            providing reliable short-range forecasts that minimized guesswork in reordering cycles. 
            Analyzing residuals (the difference between forecasted and actual sales) underscored 
            that some lines were strongly sensitive to region-specific holidays. 
            Armed with these insights, the retailer fine-tuned its marketing in historically 
            slow months and saved an estimated 10% on rush shipping costs.
          </p>
          <div id="forecastChart" class="vis-container"></div>
          <p>
            <em>Visualization: Actual &amp; Forecasted Sales with Error Bounds</em><br/>
            In the chart, the bars depict actual monthly sales for three product categories, 
            while the lines show predicted volumes. The shaded regions around the lines 
            represent 95% confidence intervals, highlighting where the model was most 
            and least certain about its predictions. This richer view gave stakeholders 
            an early warning mechanism for potential under- or over-stocking events.
          </p>
        </div>
      </div>

      <!-- Project 3: Advanced Customer Segmentation in E-Commerce -->
      <div class="project-card" data-aos="fade-up" data-aos-duration="900" data-aos-delay="300">
        <div class="project-details animated-panel">
          <h3>3. Advanced Customer Segmentation in E-Commerce</h3>
          <p>
            <strong>Project Overview:</strong>
            Leveraging around one million anonymized user sessions from an online marketplace, 
            I aimed to uncover distinct behavioral segments. By analyzing clickstreams, 
            purchase frequency, and average order value, I hoped to reveal high-value shoppers, 
            infrequent but heavy spenders, and other subgroups. The final goal: 
            deliver marketing teams a clear roadmap for better-targeted campaigns.
          </p>
          <p>
            <strong>Process:</strong>
            After merging session logs with transaction data (matching user IDs), I engineered 
            multiple features—like session length, recency (days since last purchase), 
            and cart abandonment rates. I experimented with K-Means, DBSCAN, 
            and hierarchical clustering, evaluating each using silhouette scores 
            (how cohesive each cluster is). K-Means with five clusters emerged 
            as the best compromise between interpretability and separation. 
            I then tracked user migration among clusters, discovering that some 
            customers gravitated from “Bargain Seeker” to “Steady Purchaser” 
            over months of consistent spending patterns.
          </p>
          <p>
            <strong>Results &amp; Insights:</strong>
            The final segmentation enabled the e-commerce platform to launch 
            cluster-specific promotions—like discounted upsell offers for “Occasional High-Spend” 
            shoppers or loyalty points for “Frequent Low-Spend” users. 
            These targeted strategies significantly boosted cross-sell rates (when a user 
            buys a related product) and improved email open rates by about 18%. 
            Monitoring cluster transitions became key to anticipating churn risk 
            (when a loyal user’s spend unexpectedly dips) and to reward rising star segments 
            at the right time.
          </p>
          <div id="clusteringChart" class="vis-container"></div>
          <p>
            <em>Visualization: Five-Cluster Distribution by Frequency &amp; Spend</em><br/>
            The scatter plot below shows five distinct clusters mapped against average monthly 
            purchases (X-axis) and mean order value (Y-axis). Color-coded markers illustrate 
            how each group’s patterns differ, with outliers occasionally falling between groups. 
            Labeled centroids provide quick reference points for marketing, clarifying how 
            each segment stands apart in both frequency and spend volume.
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- Contact Section -->
  <section class="contact-section" id="contact">
    <div class="section-container" data-aos="fade-up" data-aos-duration="900">
      <h2>Contact</h2>
      <p>
        I appreciate your interest in my portfolio. If you have a data challenge 
        that could benefit from local, Python-based development and thorough 
        analytics, please reach out to learn more or to discuss possible 
        collaborations.
      </p>
      <p>
        <strong>Email:</strong> <a href="mailto:dmindlin824@gmail.com">dmindlin824@gmail.com</a><br/>
        <strong>Phone:</strong> <a href="tel:8186658871">818-665-8871</a><br/>
        <strong>LinkedIn:</strong> 
        <a href="https://www.linkedin.com/in/daniel-mindlin" target="_blank">
          linkedin.com/in/daniel-mindlin</a>
      </p>
    </div>
  </section>

  <!-- Footer -->
  <footer class="site-footer" data-aos="fade-up" data-aos-duration="700">
    <p>&copy; 2025 Data by Daniel. All rights reserved.</p>
  </footer>

  <!-- AOS JS -->
  <script src="https://unpkg.com/aos@2.3.1/dist/aos.js"></script>
  <!-- Main JS -->
  <script>
    AOS.init();

    /**************************************************************************/
    /*  Project 1: Sentiment Analysis on 1.6 Million Tweets                  */
    /**************************************************************************/
    if (document.getElementById('textAnalysisChart')) {
      const months = ["Jan", "Feb", "Mar", "Apr", "May", "Jun"];
      // Average sentiment: -1 to +1
      const avgSentiment = [-0.15, 0.0, 0.1, 0.05, 0.2, 0.25];
      // Retweet counts for each month
      const retweetVolume = [100000, 130000, 180000, 160000, 200000, 250000];

      const sentimentTrace = {
        x: months,
        y: avgSentiment,
        name: "Avg Sentiment",
        mode: "lines+markers",
        yaxis: 'y1',
        line: { color: "#007AFF" }
      };

      const retweetTrace = {
        x: months,
        y: retweetVolume,
        name: "Retweet Volume",
        mode: "lines+markers",
        yaxis: 'y2',
        line: { color: "#FF2D55" }
      };

      const layoutSent = {
        title: "Monthly Average Sentiment & Retweet Volume",
        xaxis: { title: "Month" },
        yaxis: {
          title: "Sentiment (-1 to +1)",
          range: [-1, 1]
        },
        yaxis2: {
          title: "Retweet Count",
          overlaying: 'y',
          side: 'right'
        },
        paper_bgcolor: "#fff",
        plot_bgcolor: "#fff"
      };

      Plotly.newPlot('textAnalysisChart', [sentimentTrace, retweetTrace], layoutSent);
    }

    /**************************************************************************/
    /*  Project 2: Time Series Forecasting for Retail Demand                 */
    /**************************************************************************/
    if (document.getElementById('forecastChart')) {
      const months2 = ["Jan", "Feb", "Mar", "Apr", "May", "Jun"];
      // Real monthly sales for 3 product categories
      const catA_actual = [2000, 2400, 2800, 2700, 3200, 3500];
      const catB_actual = [500, 550, 600, 580, 750, 800];
      const catC_actual = [900, 950, 1000, 1100, 1200, 1350];

      // Forecast predictions for those categories
      const catA_pred = [1900, 2350, 2900, 2650, 3150, 3400];
      const catB_pred = [480, 530, 610, 590, 730, 790];
      const catC_pred = [920, 900, 1050, 1080, 1240, 1300];

      // Confidence intervals (just an example)
      const catA_upper = [2100, 2500, 3050, 2800, 3350, 3600];
      const catA_lower = [1800, 2250, 2700, 2500, 3000, 3250];

      const layoutForecast = {
        title: "Actual & Forecasted Monthly Sales (3 Categories)",
        xaxis: { title: "Month" },
        yaxis: { title: "Sales (Units)" },
        paper_bgcolor: "#fff",
        plot_bgcolor: "#fff"
      };

      // Category A
      const catA_ActualTrace = {
        x: months2,
        y: catA_actual,
        name: "Cat A Actual",
        mode: "lines+markers",
        line: { color: "#007AFF" }
      };
      const catA_PredTrace = {
        x: months2,
        y: catA_pred,
        name: "Cat A Forecast",
        mode: "lines+markers",
        line: { color: "#34C759" }
      };
      const catA_UpperTrace = {
        x: months2,
        y: catA_upper,
        fill: null,
        mode: "lines",
        line: { color: "rgba(52,199,89,0.3)", width: 0 },
        showlegend: false
      };
      const catA_LowerTrace = {
        x: months2,
        y: catA_lower,
        fill: 'tonexty',
        fillcolor: "rgba(52,199,89,0.1)",
        mode: "lines",
        line: { color: "rgba(52,199,89,0.3)", width: 0 },
        name: "Confidence (Cat A)"
      };

      // Category B
      const catB_ActualTrace = {
        x: months2,
        y: catB_actual,
        name: "Cat B Actual",
        mode: "lines+markers",
        line: { color: "#FF9500" }
      };
      const catB_PredTrace = {
        x: months2,
        y: catB_pred,
        name: "Cat B Forecast",
        mode: "lines+markers",
        line: { color: "rgba(255,149,0, 0.6)" }
      };

      // Category C
      const catC_ActualTrace = {
        x: months2,
        y: catC_actual,
        name: "Cat C Actual",
        mode: "lines+markers",
        line: { color: "#5856D6" }
      };
      const catC_PredTrace = {
        x: months2,
        y: catC_pred,
        name: "Cat C Forecast",
        mode: "lines+markers",
        line: { color: "rgba(88,86,214, 0.7)" }
      };

      Plotly.newPlot('forecastChart', [
        catA_UpperTrace, catA_LowerTrace, // confidence band catA
        catA_ActualTrace, catA_PredTrace,
        catB_ActualTrace, catB_PredTrace,
        catC_ActualTrace, catC_PredTrace,
      ], layoutForecast);
    }

    /**************************************************************************/
    /*  Project 3: Advanced Customer Segmentation in E-Commerce              */
    /**************************************************************************/
    if (document.getElementById('clusteringChart')) {
      // Example of 5 clusters
      const clusterA = {
        x: [12, 13, 11, 10],
        y: [70, 75, 80, 68],
        mode: "markers",
        name: "Cluster A: Low-Frequency, Low-Spend",
        marker: { color: "#FF2D55", size: 10 }
      };
      const clusterB = {
        x: [25, 28, 27, 26],
        y: [140, 135, 150, 155],
        mode: "markers",
        name: "Cluster B: Mid-Frequency, Low-Spend",
        marker: { color: "#FF9500", size: 10 }
      };
      const clusterC = {
        x: [32, 35, 34, 33],
        y: [200, 210, 190, 220],
        mode: "markers",
        name: "Cluster C: Mid-Frequency, Mid-Spend",
        marker: { color: "#007AFF", size: 10 }
      };
      const clusterD = {
        x: [45, 48, 46, 49],
        y: [350, 370, 340, 390],
        mode: "markers",
        name: "Cluster D: High-Frequency, Med-Spend",
        marker: { color: "#34C759", size: 10 }
      };
      const clusterE = {
        x: [58, 60, 62, 64],
        y: [600, 620, 610, 640],
        mode: "markers",
        name: "Cluster E: High-Frequency, High-Spend",
        marker: { color: "#5856D6", size: 10 }
      };

      const layoutClust = {
        title: "Five-Cluster Distribution by Frequency & Average Spend",
        xaxis: { title: "Purchases per Month" },
        yaxis: { title: "Avg Order Value (USD)" },
        paper_bgcolor: "#fff",
        plot_bgcolor: "#fff"
      };

      Plotly.newPlot('clusteringChart', [clusterA, clusterB, clusterC, clusterD, clusterE], layoutClust);
    }
  </script>
</body>
</html>
